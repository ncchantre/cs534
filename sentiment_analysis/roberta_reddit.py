# -*- coding: utf-8 -*-
"""RoBERTa_Reddit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SKb4bLfYxwPkKm_wfP6o5RHafjCZ2ZZx
"""

!pip install transformers

from google.colab import drive
drive.mount('/content/drive/')
path = 'drive/My Drive/CS534 Group Project/Files/'

from transformers import pipeline
model = "siebert/sentiment-roberta-large-english"
sentiment_analysis = pipeline("sentiment-analysis", model=model, tokenizer=model, max_length=512, truncation=True)

df.drop('Unnamed: 0', axis=1, inplace=True)

import pandas as pd
df = pd.read_csv(path + "RS_2022_Amazon_with_subreddits_no_stopwords.csv")

print(df['Subreddit'][0])
print(df['Body'][0])

df['Sentiment'] = df['Body'].apply(lambda row: sentiment_analysis(row))

df.to_csv("RS_2022_RoBERTa.csv")

print(sentiment_analysis(df['Body'][0]))

import pandas as pd

amazon_reviews = pd.read_csv(path + "sentiment_analysis_labeled_amazon.csv")
amazon_reviews_R = pd.read_csv("amazon_reviews_RoBERTA.csv")

def convert_from_label(entry):
  if entry == 'NEGATIVE':
    return 0
  else:
    return 1

amazon_reviews_R['Sentiment'] = amazon_reviews_R['label'].apply(convert_from_label)

from sklearn import metrics

print(f"Accuracy: {metrics.accuracy_score(amazon_reviews['Sentiment'], amazon_reviews_R['Sentiment'])}")
print(f"Precision: {metrics.precision_score(amazon_reviews['Sentiment'], amazon_reviews_R['Sentiment'])}")
print(f"Recall: {metrics.recall_score(amazon_reviews['Sentiment'], amazon_reviews_R['Sentiment'])}")
print(f"F1: {metrics.f1_score(amazon_reviews['Sentiment'], amazon_reviews_R['Sentiment'])}")
print(f"MCC: {metrics.matthews_corrcoef(amazon_reviews['Sentiment'], amazon_reviews_R['Sentiment'])}")

"""## Data Filtering/Analysis Below"""

import numpy as np
np.savetxt("subreddits.csv", df.Subreddit.unique(), fmt='%s')

# Score distribution
print(df.Score.describe())

df_filtered = df[df['Score'] >= 6.0]
print(df_filtered.Score.describe())

df_filtered['Body'] = df_filtered['Body'].str.replace('[^a-zA-Z\s]+', '')
df_filtered['Body'] = df_filtered['Body'].str.replace('\s+', ' ')

# Stop words to filter out
stop_words = ['a', 'an', 'and', 'about', 'are', 'as', 'at', 'be', 'but', 'by',
              'for', 'if', 'from', 'Hi', 'hi', 'Hey', 'hey', 'has', 'I', 'Im', 'i', 'im'
              'in', 'into', 'is', 'it', 'no', 'not', 'of', 'on', 'or','such',
              'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to',
              'was', 'will', 'with', 'you', 'youve', 'youre', 'your']

def filter_stop_words(sentence):
  words = sentence.split()
  filtered = [word for word in words if word not in stop_words and len(word) <= 20]
  return " ".join(filtered)

df_filtered['Body'].apply(filter_stop_words)

df_filtered['Body']

print(sentiment_analysis(":)"))
print(sentiment_analysis(":("))
print(sentiment_analysis(":D"))
print(sentiment_analysis(":-)"))